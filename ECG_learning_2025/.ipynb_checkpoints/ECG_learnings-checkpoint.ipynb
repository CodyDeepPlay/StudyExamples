{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c0abff6-22be-4d7b-8954-3484227c1853",
   "metadata": {},
   "source": [
    "# ECG segmentation with Physionet dataset\n",
    "This file is showing an example of how to load the ECG data from the physionet dataset that was originally downloaded from https://www.physionet.org/content/qtdb/1.0.0/\n",
    "\n",
    "This is a exercise of refactorize my code developed couple of years ago.\n",
    "\n",
    "This file contains using different machine learning methods to conduct signal segmentation.\n",
    "\n",
    "\n",
    "Make sure to refer to 'requirements.txt' to use the packages with the listed version. With some other versions of packages, it may not be compatible with 'wfdb' package, most likely the newer version of'numpy' package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0f83bf5-1abd-4c89-96c3-29bec98f1f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wfdb  # waveform database package, a library of tools for reading, writing, and processing WFDB signals and annotations.\n",
    "\n",
    "from lib import HelpferFunctions as hf  # custom module with helperfunctions needed here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b573f0-a0e4-4d7a-a114-f37153847f91",
   "metadata": {},
   "source": [
    "### Reorganize data files\n",
    "Each data file contains recordings from two channels, these two channels are ECG recordings collected at the same time, and should be two different recording electrodes. Each data file may include different length of samples. \n",
    "\n",
    "Thus, here, we figure out what is the minimum length of a recording, and truncate all the data using this minimum length and reorganize data into a big single dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1b91f1-35f8-49aa-8337-0fccdb583e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of recording files are: 105\n",
      "Minimum signal length is: 224993\n"
     ]
    }
   ],
   "source": [
    "#%% load all the files\n",
    "data_path   = 'qt-database-1.0.0'  # this cardiac data was downloaded and saved locally\n",
    "all_file_names = os.listdir(data_path)\n",
    "\n",
    "min_sig_len = None\n",
    "all_pu1s =[] # get all the pu1 files\n",
    "\n",
    "for a_file in all_file_names:\n",
    "    if 'pu1' in a_file:\n",
    "        a_file_name=a_file.split('.')       \n",
    "        record_name = a_file_name[0] # just the file name, not including extension\n",
    "        \n",
    "        if record_name not in all_pu1s:  # make sure not dupilcated names, so one file will not be added twice\n",
    "            all_pu1s.append(record_name) # only add the file name, not extension\n",
    "            record_path = os.path.join(data_path, record_name)\n",
    "            record = wfdb.rdrecord(record_path)\n",
    "            signals, fields = wfdb.rdsamp(record_path)\n",
    "            fs = fields['fs']\n",
    "            length = fields['sig_len']\n",
    "            \n",
    "            if min_sig_len is not None:\n",
    "                min_sig_len = min(min_sig_len, length)\n",
    "            else:                \n",
    "                min_sig_len = length\n",
    "\n",
    "print(\"Total number of recording files are:\", len(all_pu1s))\n",
    "print(\"Minimum signal length is:\" , min_sig_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9c973a-f500-4c5d-be07-33762f97e410",
   "metadata": {},
   "source": [
    "Now reorganize separate recordings into single data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba41bdeb-b92f-44eb-a7cf-aa64225f449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file shape is [number of observations, time stamps, number of features]\n",
      "(105, 224993, 2)\n",
      "Annotation file shape is [number of observations, time stamps]\n",
      "(105, 224993)\n"
     ]
    }
   ],
   "source": [
    "All_data_list = []  # create a space to host all the data\n",
    "All_annotation_list = [] # host all the ECG signal annotation\n",
    "\n",
    "for record_name in all_pu1s:\n",
    "    record_path = os.path.join(data_path, record_name)\n",
    "    record = wfdb.rdrecord(record_path)        # read a single file\n",
    "    signals, fields = wfdb.rdsamp(record_path) # extract the signals from a single file\n",
    "   \n",
    "    # read the annotation for a single file\n",
    "    annotation   = wfdb.rdann(record_path, 'pu1')\n",
    "    annot_expand = hf.expand_annotation(annotation.sample, annotation.symbol, length)\n",
    "    \n",
    "    # use the smallest signal length to truncate all the data, so that \n",
    "    # we can contatenate all the signal recordings in a single large dataset\n",
    "    signals2add = signals[0:min_sig_len,:]\n",
    "    annotation2add = annot_expand[0:min_sig_len]\n",
    "    \n",
    "    All_data_list.append(signals2add)\n",
    "    All_annotation_list.append(annotation2add)\n",
    "    \n",
    "All_data = np.asarray(All_data_list)  # size(num_obs, time_stamps, n_features)\n",
    "All_annotation = np.asarray(All_annotation_list)  # size(num_obs, time_stamps)\n",
    "\n",
    "print(\"Data file shape is [number of observations, time stamps, number of features]\")\n",
    "print(All_data.shape)\n",
    "print(\"Annotation file shape is [number of observations, time stamps]\")\n",
    "print(All_annotation.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e618bae-b515-4edb-8270-848c14990f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
